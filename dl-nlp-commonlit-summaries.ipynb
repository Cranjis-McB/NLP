{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db893e1e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.010655,
     "end_time": "2023-07-23T06:15:16.953523",
     "exception": false,
     "start_time": "2023-07-23T06:15:16.942868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Goal:\n",
    "\n",
    "* The immediate goal is to setup this notebook for training, Inference and submission for LB evaluation.\n",
    "\n",
    "We'll set more goals once we achieve this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f85a2e",
   "metadata": {
    "papermill": {
     "duration": 0.009851,
     "end_time": "2023-07-23T06:15:16.973945",
     "exception": false,
     "start_time": "2023-07-23T06:15:16.964094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's Create a Controller variable for Training/Submission Mode.\n",
    "\n",
    "* Set **True** for Submission Mode.\n",
    "* Set **False** for Training Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3771e5b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:16.996494Z",
     "iopub.status.busy": "2023-07-23T06:15:16.995817Z",
     "iopub.status.idle": "2023-07-23T06:15:17.008702Z",
     "shell.execute_reply": "2023-07-23T06:15:17.007849Z"
    },
    "papermill": {
     "duration": 0.026874,
     "end_time": "2023-07-23T06:15:17.011208",
     "exception": false,
     "start_time": "2023-07-23T06:15:16.984334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook is on submission Mode...\n",
      "Make sure to turn off the Internet...\n"
     ]
    }
   ],
   "source": [
    "# True if you want to submit the Notebook\n",
    "isSubmit = True\n",
    "\n",
    "if isSubmit:\n",
    "    print(f'This notebook is on submission Mode...')\n",
    "    print(f'Make sure to turn off the Internet...')\n",
    "else:\n",
    "    print(f'This notebook is on Training Mode...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97a874",
   "metadata": {
    "papermill": {
     "duration": 0.010093,
     "end_time": "2023-07-23T06:15:17.031511",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.021418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-1: Read and Understand Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c80e87",
   "metadata": {
    "papermill": {
     "duration": 0.009869,
     "end_time": "2023-07-23T06:15:17.051997",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.042128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we have two type of files: \n",
    "1. **<span style=\"color:red\">Prompts:</span>** It contains the Question, a title about the text, and the text that needs to be summarized.\n",
    "2. **<span style=\"color:red\">Summaries:</span>** This includes the text summarized by the students, along with the corresponding prompt id and target scores for both content and wording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e79123b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:17.075942Z",
     "iopub.status.busy": "2023-07-23T06:15:17.074330Z",
     "iopub.status.idle": "2023-07-23T06:15:17.080157Z",
     "shell.execute_reply": "2023-07-23T06:15:17.079323Z"
    },
    "papermill": {
     "duration": 0.019114,
     "end_time": "2023-07-23T06:15:17.082080",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.062966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "import pandas as pd\n",
    "\n",
    "if not isSubmit:\n",
    "    # Train\n",
    "    prompt_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "    summary_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "\n",
    "    print(f'\\nLength of Train Prompt df: {len(prompt_df)}')\n",
    "    print(f'Length of Train Summary df: {len(summary_df)}\\n')\n",
    "\n",
    "    # Display\n",
    "    summary_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92b8b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:17.104164Z",
     "iopub.status.busy": "2023-07-23T06:15:17.103416Z",
     "iopub.status.idle": "2023-07-23T06:15:17.108172Z",
     "shell.execute_reply": "2023-07-23T06:15:17.107269Z"
    },
    "papermill": {
     "duration": 0.017946,
     "end_time": "2023-07-23T06:15:17.110250",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.092304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    # Distribution of the Prompt Questions.\n",
    "    print(summary_df['prompt_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be17cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:17.133937Z",
     "iopub.status.busy": "2023-07-23T06:15:17.132332Z",
     "iopub.status.idle": "2023-07-23T06:15:17.137547Z",
     "shell.execute_reply": "2023-07-23T06:15:17.136684Z"
    },
    "papermill": {
     "duration": 0.018323,
     "end_time": "2023-07-23T06:15:17.139511",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.121188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    # Number of Unique Students\n",
    "    print(len(summary_df['student_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dae5e2",
   "metadata": {
    "papermill": {
     "duration": 0.010175,
     "end_time": "2023-07-23T06:15:17.159741",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.149566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**So the Training data contains only 4 Prompt Questions that is being asked to 7165 students.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce858cf9",
   "metadata": {
    "papermill": {
     "duration": 0.009853,
     "end_time": "2023-07-23T06:15:17.179912",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.170059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now Let's understand the Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c91d22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:17.202756Z",
     "iopub.status.busy": "2023-07-23T06:15:17.201257Z",
     "iopub.status.idle": "2023-07-23T06:15:17.206888Z",
     "shell.execute_reply": "2023-07-23T06:15:17.206020Z"
    },
    "papermill": {
     "duration": 0.018862,
     "end_time": "2023-07-23T06:15:17.208974",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.190112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit: \n",
    "    # Describe\n",
    "    describe_content_df = summary_df['content'].describe()\n",
    "    describe_wording_df = summary_df['wording'].describe()\n",
    "\n",
    "    print(pd.concat([describe_content_df, describe_wording_df], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66283100",
   "metadata": {
    "papermill": {
     "duration": 0.01016,
     "end_time": "2023-07-23T06:15:17.229184",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.219024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* The value of **Content** ranging from -1.72 to 3.90.\n",
    "* Value of the **Wording** is ranging from -1.96 to 4.31.\n",
    "\n",
    "It surely has two classes (Content and Wording) and each class has a continuous output. This problem can be put into the category of **Two-Class Regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6bc5d2",
   "metadata": {
    "papermill": {
     "duration": 0.009774,
     "end_time": "2023-07-23T06:15:17.248923",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.239149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's have an overall idea about the number of words (or tokens) in summary text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595097e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:17.270654Z",
     "iopub.status.busy": "2023-07-23T06:15:17.269887Z",
     "iopub.status.idle": "2023-07-23T06:15:17.275905Z",
     "shell.execute_reply": "2023-07-23T06:15:17.274920Z"
    },
    "papermill": {
     "duration": 0.019015,
     "end_time": "2023-07-23T06:15:17.277968",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.258953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    text_length = summary_df['text'].apply(lambda x: len(x.split(' ')))\n",
    "    print(text_length.describe())\n",
    "    print('\\n')\n",
    "\n",
    "    # Lets Visualize the same.\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    # Create a histogram using Matplotlib\n",
    "    plt.figure(figsize = (3, 3))\n",
    "    plt.hist(text_length, bins=10, edgecolor='k')\n",
    "    plt.xlabel('Text Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of the Text Length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9894c51",
   "metadata": {
    "papermill": {
     "duration": 0.010119,
     "end_time": "2023-07-23T06:15:17.298723",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.288604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The average text summary length is approximately 76 tokens, with a standard deviation of 54 tokens. Most of the text summaries have a length of less than 200 tokens. That is still in the limit of **BERT** and related models, which accept a **maximum of 512 tokens**. In Future, we might use some of the contextual information from the Prompt text to utilize this token gap properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b5c1c",
   "metadata": {
    "papermill": {
     "duration": 0.009802,
     "end_time": "2023-07-23T06:15:17.318622",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.308820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-2: Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05900373",
   "metadata": {
    "papermill": {
     "duration": 0.009897,
     "end_time": "2023-07-23T06:15:17.338783",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.328886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now Let's define the Dataset Class.\n",
    "\n",
    "The Dataset class in Natural Language Processing (NLP) serves as a fundamental data structure that helps manage and handle textual data for training and evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3651d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:17.359965Z",
     "iopub.status.busy": "2023-07-23T06:15:17.359701Z",
     "iopub.status.idle": "2023-07-23T06:15:23.146461Z",
     "shell.execute_reply": "2023-07-23T06:15:23.145395Z"
    },
    "papermill": {
     "duration": 5.800862,
     "end_time": "2023-07-23T06:15:23.149761",
     "exception": false,
     "start_time": "2023-07-23T06:15:17.348899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class CommonLitSummaryDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 summary_df,\n",
    "                 prompt_df, \n",
    "                 model_name, \n",
    "                 max_length = 256,\n",
    "                 isTest = False\n",
    "                ):\n",
    "        self.summary_df = summary_df\n",
    "        self.prompt_df = prompt_df\n",
    "        self.max_length = max_length\n",
    "        self.tokz = AutoTokenizer.from_pretrained('/kaggle/input/commonlit-summaries-all-tokenizers/bert_base_cased_tokenizer')\n",
    "        self.isTest = isTest\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.summary_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get the Summary and It's Corresponding Question\n",
    "        txt_summary = self.summary_df['text'].iloc[idx]\n",
    "        prompt_id = self.summary_df['prompt_id'].iloc[idx]\n",
    "        txt_question = self.prompt_df[self.prompt_df['prompt_id'] == prompt_id]['prompt_question'].iloc[0]\n",
    "        \n",
    "        # Concat the Question and Summary.\n",
    "        input_text = 'QUESTION: ' + txt_question + 'SUMMARY: ' + txt_summary\n",
    "        \n",
    "        # Convert the text data into Corresponding Numerical Embeddings.\n",
    "        encodings = self.tokz.encode_plus(input_text, \n",
    "                                          add_special_tokens=True, \n",
    "                                          max_length = self.max_length, \n",
    "                                          padding = 'max_length', \n",
    "                                          truncation = True, \n",
    "                                          return_tensors = 'pt'\n",
    "                                         )\n",
    "        input_ids = encodings['input_ids'].squeeze()\n",
    "        attention_mask = encodings['attention_mask'].squeeze()\n",
    "        \n",
    "        # For Test set, No labels will be available\n",
    "        if self.isTest:\n",
    "            return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "            \n",
    "        # Labels\n",
    "        label = torch.tensor(self.summary_df.iloc[idx][-2:].tolist())\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f15aac",
   "metadata": {
    "papermill": {
     "duration": 0.010023,
     "end_time": "2023-07-23T06:15:23.170455",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.160432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before Initialising the Class, We have to split the dataset into two categories. 1) Train 2) Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f65b5bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:23.192216Z",
     "iopub.status.busy": "2023-07-23T06:15:23.191719Z",
     "iopub.status.idle": "2023-07-23T06:15:23.196937Z",
     "shell.execute_reply": "2023-07-23T06:15:23.195947Z"
    },
    "papermill": {
     "duration": 0.018352,
     "end_time": "2023-07-23T06:15:23.198921",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.180569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    # Split the dataframe into train and validation sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    train_df, valid_df = train_test_split(summary_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8be6dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:23.220477Z",
     "iopub.status.busy": "2023-07-23T06:15:23.220204Z",
     "iopub.status.idle": "2023-07-23T06:15:23.225895Z",
     "shell.execute_reply": "2023-07-23T06:15:23.224889Z"
    },
    "papermill": {
     "duration": 0.018615,
     "end_time": "2023-07-23T06:15:23.227915",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.209300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "\n",
    "    # Initialize Dataset Classes\n",
    "    commonlit_summary_train_ds = CommonLitSummaryDataset(train_df,\n",
    "                                                         prompt_df, \n",
    "                                                         model_name = 'bert-base-cased', \n",
    "                                                         max_length = 256\n",
    "                                                        )\n",
    "    commonlit_summary_valid_ds = CommonLitSummaryDataset(valid_df, \n",
    "                                                         prompt_df,  \n",
    "                                                         model_name = 'bert-base-cased', \n",
    "                                                         max_length = 256\n",
    "                                                        )\n",
    "    print(f'Train - {len(commonlit_summary_train_ds)}, Test - {len(commonlit_summary_valid_ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5cd7a",
   "metadata": {
    "papermill": {
     "duration": 0.010026,
     "end_time": "2023-07-23T06:15:23.248298",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.238272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's Visualize one Sample to see the working of our Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d0c3ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:23.270940Z",
     "iopub.status.busy": "2023-07-23T06:15:23.270119Z",
     "iopub.status.idle": "2023-07-23T06:15:23.275898Z",
     "shell.execute_reply": "2023-07-23T06:15:23.275051Z"
    },
    "papermill": {
     "duration": 0.01898,
     "end_time": "2023-07-23T06:15:23.277826",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.258846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "\n",
    "    # Tokenizer\n",
    "    tokz =  AutoTokenizer.from_pretrained('/kaggle/input/commonlit-summaries-all-tokenizers/bert_base_cased_tokenizer')\n",
    "\n",
    "    print(f'------ Input ----------\\n')\n",
    "    sample = commonlit_summary_train_ds[0]\n",
    "    print(tokz.decode(sample['input_ids']))\n",
    "\n",
    "    print(f'\\n------ Labels ----------\\n')\n",
    "    labels = sample['labels']\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1878a1",
   "metadata": {
    "papermill": {
     "duration": 0.010635,
     "end_time": "2023-07-23T06:15:23.298679",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.288044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataloader:**\n",
    "\n",
    "Dataloader allows us to group multiple samples into batches, enabling parallel processing and more efficient GPU utilization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cae5546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:23.321568Z",
     "iopub.status.busy": "2023-07-23T06:15:23.321282Z",
     "iopub.status.idle": "2023-07-23T06:15:23.326513Z",
     "shell.execute_reply": "2023-07-23T06:15:23.325462Z"
    },
    "papermill": {
     "duration": 0.019225,
     "end_time": "2023-07-23T06:15:23.328468",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.309243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if not isSubmit:\n",
    "    # Create a data loader for the dataset\n",
    "    batch_size = 16\n",
    "    train_dataloader = DataLoader(commonlit_summary_train_ds, batch_size=batch_size, shuffle=True)\n",
    "    eval_dataloader = DataLoader(commonlit_summary_valid_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c47c9b",
   "metadata": {
    "papermill": {
     "duration": 0.010777,
     "end_time": "2023-07-23T06:15:23.350295",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.339518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-3: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b78f8cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:23.374090Z",
     "iopub.status.busy": "2023-07-23T06:15:23.372515Z",
     "iopub.status.idle": "2023-07-23T06:15:31.851642Z",
     "shell.execute_reply": "2023-07-23T06:15:31.850571Z"
    },
    "papermill": {
     "duration": 8.493304,
     "end_time": "2023-07-23T06:15:31.854095",
     "exception": false,
     "start_time": "2023-07-23T06:15:23.360791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "model_nm = 'bert-base-cased'\n",
    "num_labels = 2\n",
    "\n",
    "if not isSubmit:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=num_labels)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"\\nTotal number of parameters: \", total_params)\n",
    "\n",
    "    total_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    print(\"Total size (bytes) of the model: \", total_size)\n",
    "    print(\"Total size (MB) of the model: \", total_size / (1024 * 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968dc49",
   "metadata": {
    "papermill": {
     "duration": 0.010914,
     "end_time": "2023-07-23T06:15:31.875699",
     "exception": false,
     "start_time": "2023-07-23T06:15:31.864785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we need to save the best model during Training based on the **MCRMSE** (mean columnwise root mean squared error) which is the Cost Function/ Metric for this Competition.\n",
    "\n",
    "Let's implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "421ec8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:31.901733Z",
     "iopub.status.busy": "2023-07-23T06:15:31.901418Z",
     "iopub.status.idle": "2023-07-23T06:15:31.906469Z",
     "shell.execute_reply": "2023-07-23T06:15:31.905572Z"
    },
    "papermill": {
     "duration": 0.022048,
     "end_time": "2023-07-23T06:15:31.908715",
     "exception": false,
     "start_time": "2023-07-23T06:15:31.886667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility: mean columnwise root mean squared error\n",
    "def mcrmse_loss(predictions, targets):\n",
    "    rmse_columnwise = torch.sqrt(torch.mean((predictions - targets)**2, dim=0))\n",
    "    return torch.mean(rmse_columnwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ccc4b",
   "metadata": {
    "papermill": {
     "duration": 0.010239,
     "end_time": "2023-07-23T06:15:31.929235",
     "exception": false,
     "start_time": "2023-07-23T06:15:31.918996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3345321c",
   "metadata": {
    "papermill": {
     "duration": 0.011531,
     "end_time": "2023-07-23T06:15:31.951256",
     "exception": false,
     "start_time": "2023-07-23T06:15:31.939725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In order to have **faster Training**, we will do the followings:\n",
    "\n",
    "1. **Enable mixed precision training** (using half-precision floating-point format or fp16). It utilizes Tensor Cores on supported NVIDIA GPUs to speed up the training process with reduced memory usage.\n",
    "\n",
    "2.  To utilize Kaggle T4/X2 GPU, we will use **DataParallel**. DataParallel allows you to train your model on multiple GPUs simultaneously, distributing the workload across all available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0edfdd94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:31.977021Z",
     "iopub.status.busy": "2023-07-23T06:15:31.976723Z",
     "iopub.status.idle": "2023-07-23T06:15:31.983236Z",
     "shell.execute_reply": "2023-07-23T06:15:31.982139Z"
    },
    "papermill": {
     "duration": 0.021726,
     "end_time": "2023-07-23T06:15:31.985743",
     "exception": false,
     "start_time": "2023-07-23T06:15:31.964017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not isSubmit:\n",
    "    \n",
    "    # Import Dataparallel and mixed precision modules\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    from torch.nn.parallel import DataParallel\n",
    "\n",
    "    # Check if GPU is available.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'DEVICE: {device}\\n')\n",
    "\n",
    "    # Used for Mixed Precision Training\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Move your model to the GPU and wrap it with DataParallel (To utilize T4X2)\n",
    "    model = model.to(device)\n",
    "    model = DataParallel(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cee7d2",
   "metadata": {
    "papermill": {
     "duration": 0.010317,
     "end_time": "2023-07-23T06:15:32.006854",
     "exception": false,
     "start_time": "2023-07-23T06:15:31.996537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's Train the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e346506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:32.029535Z",
     "iopub.status.busy": "2023-07-23T06:15:32.029226Z",
     "iopub.status.idle": "2023-07-23T06:15:32.044125Z",
     "shell.execute_reply": "2023-07-23T06:15:32.043088Z"
    },
    "papermill": {
     "duration": 0.029132,
     "end_time": "2023-07-23T06:15:32.046608",
     "exception": false,
     "start_time": "2023-07-23T06:15:32.017476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "if not isSubmit:\n",
    "    # Prepare optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    NUM_EPOCHS = 15\n",
    "\n",
    "    best_eval_loss = float('inf')  # Initialize the best evaluation loss to infinity\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        total_loss = 0\n",
    "        model.train() # Set the model to Training mode\n",
    "\n",
    "        for batch in tqdm(train_dataloader):\n",
    "\n",
    "            with autocast():\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                # Forward loop\n",
    "                optimizer.zero_grad() # Ensures Gradient doesn't accumulate.\n",
    "                predictions = model(input_ids=input_ids,\n",
    "                                    attention_mask=attention_mask, \n",
    "                                    labels=labels\n",
    "                                   ).logits\n",
    "\n",
    "                # Compute MCRMSE loss\n",
    "                loss = mcrmse_loss(predictions, labels)\n",
    "\n",
    "            # BackProp\n",
    "            scaler.scale(loss).backward()  # Scale the loss value\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Accumulate the Loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Calculate epoch-level metrics\n",
    "        epoch_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # Print epoch-level metrics\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "         # Evaluation\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        eval_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_dataloader:\n",
    "                with autocast():\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['labels'].to(device)\n",
    "\n",
    "                    predictions = model(input_ids=input_ids,\n",
    "                                        attention_mask=attention_mask, \n",
    "                                        labels=labels\n",
    "                                       ).logits\n",
    "                    loss = mcrmse_loss(predictions, labels)\n",
    "\n",
    "                    eval_loss += loss.item()\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "\n",
    "        # Print evaluation metrics\n",
    "        print(f\"Eval Loss: {eval_epoch_loss:.4f}\")\n",
    "\n",
    "        # Save the Best Model\n",
    "        if eval_epoch_loss < best_eval_loss:\n",
    "            print(f'--------------------------------------')\n",
    "            print(f'Found the best model at Epoch {epoch+1}')\n",
    "            print(f'Validation Loss reduced from {best_eval_loss:.4f} to {eval_epoch_loss:.4f}')\n",
    "            best_eval_loss = eval_epoch_loss\n",
    "            print(f'Saving the best model.')\n",
    "            print(f'--------------------------------------\\n')\n",
    "            \n",
    "            # Access the actual model from the DataParallel object\n",
    "            actual_model = model.module\n",
    "            # Save\n",
    "            actual_model.save_pretrained(\"vanilla_bert_base_cased\")\n",
    "            #torch.save(model.state_dict(), \"vanilla_bert_base_cased.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c94625",
   "metadata": {
    "papermill": {
     "duration": 0.010296,
     "end_time": "2023-07-23T06:15:32.067630",
     "exception": false,
     "start_time": "2023-07-23T06:15:32.057334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Step-4: Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7eb2e",
   "metadata": {
    "papermill": {
     "duration": 0.010175,
     "end_time": "2023-07-23T06:15:32.088824",
     "exception": false,
     "start_time": "2023-07-23T06:15:32.078649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the Best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a7ce94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:32.111383Z",
     "iopub.status.busy": "2023-07-23T06:15:32.111086Z",
     "iopub.status.idle": "2023-07-23T06:15:43.369207Z",
     "shell.execute_reply": "2023-07-23T06:15:43.368148Z"
    },
    "papermill": {
     "duration": 11.272038,
     "end_time": "2023-07-23T06:15:43.371675",
     "exception": false,
     "start_time": "2023-07-23T06:15:32.099637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = '/kaggle/input/commonlit-summaries-all-models/vanilla_bert_base_cased'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Check if GPU is available.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'DEVICE: {device}\\n')\n",
    "\n",
    "# Model to the Device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3705f",
   "metadata": {
    "papermill": {
     "duration": 0.01048,
     "end_time": "2023-07-23T06:15:43.393971",
     "exception": false,
     "start_time": "2023-07-23T06:15:43.383491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare Test Data Loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "741e2448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:43.416582Z",
     "iopub.status.busy": "2023-07-23T06:15:43.415642Z",
     "iopub.status.idle": "2023-07-23T06:15:43.494922Z",
     "shell.execute_reply": "2023-07-23T06:15:43.494014Z"
    },
    "papermill": {
     "duration": 0.092685,
     "end_time": "2023-07-23T06:15:43.497076",
     "exception": false,
     "start_time": "2023-07-23T06:15:43.404391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7c9e13ce3550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Test DF's.\n",
    "prompt_test_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\n",
    "summary_test_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "\n",
    "# Initialize Dataset Classes\n",
    "commonlit_summary_test_ds = CommonLitSummaryDataset(summary_test_df,\n",
    "                                                    prompt_test_df, \n",
    "                                                    model_name = 'bert-base-cased', \n",
    "                                                    max_length = 256,\n",
    "                                                    isTest = True\n",
    "                                                    )\n",
    "# Test Dataloader\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(commonlit_summary_test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d572ee7",
   "metadata": {
    "papermill": {
     "duration": 0.01051,
     "end_time": "2023-07-23T06:15:43.518724",
     "exception": false,
     "start_time": "2023-07-23T06:15:43.508214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b6bec5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:43.541829Z",
     "iopub.status.busy": "2023-07-23T06:15:43.541023Z",
     "iopub.status.idle": "2023-07-23T06:15:46.116661Z",
     "shell.execute_reply": "2023-07-23T06:15:46.115434Z"
    },
    "papermill": {
     "duration": 2.589344,
     "end_time": "2023-07-23T06:15:46.118888",
     "exception": false,
     "start_time": "2023-07-23T06:15:43.529544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Eval model\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():  # Disable gradient computation during inference\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Predictions\n",
    "        predictions_batch = model(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask\n",
    "                                 ).logits\n",
    "        \n",
    "        # Collect predictions from this batch\n",
    "        predictions.extend(predictions_batch.cpu().tolist())\n",
    "        \n",
    "        \n",
    "# Convert to numpy\n",
    "import numpy as np\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725bae2",
   "metadata": {
    "papermill": {
     "duration": 0.011019,
     "end_time": "2023-07-23T06:15:46.141597",
     "exception": false,
     "start_time": "2023-07-23T06:15:46.130578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae571810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T06:15:46.165794Z",
     "iopub.status.busy": "2023-07-23T06:15:46.164806Z",
     "iopub.status.idle": "2023-07-23T06:15:46.183392Z",
     "shell.execute_reply": "2023-07-23T06:15:46.182451Z"
    },
    "papermill": {
     "duration": 0.032842,
     "end_time": "2023-07-23T06:15:46.185625",
     "exception": false,
     "start_time": "2023-07-23T06:15:46.152783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>-1.450631</td>\n",
       "      <td>-1.514663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>-1.450113</td>\n",
       "      <td>-1.521089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>-1.447816</td>\n",
       "      <td>-1.523844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>-1.456676</td>\n",
       "      <td>-1.529542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id   content   wording\n",
       "0  000000ffffff -1.450631 -1.514663\n",
       "1  111111eeeeee -1.450113 -1.521089\n",
       "2  222222cccccc -1.447816 -1.523844\n",
       "3  333333dddddd -1.456676 -1.529542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data = {\n",
    "    'student_id': summary_test_df['student_id'].tolist(),\n",
    "    'content': predictions[:,0],\n",
    "    'wording': predictions[:,1]\n",
    "}\n",
    "submission_df = pd.DataFrame(data)\n",
    "\n",
    "# Display\n",
    "display(submission_df.head())\n",
    "\n",
    "# Save it for Submission\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb7d0f",
   "metadata": {
    "papermill": {
     "duration": 0.010899,
     "end_time": "2023-07-23T06:15:46.208769",
     "exception": false,
     "start_time": "2023-07-23T06:15:46.197870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TODO:**\n",
    "\n",
    "* FP16 Training <font color=\"green\">&#10004;</font>\n",
    "* Utilize Both of the GPU's <font color=\"green\">&#10004;</font>\n",
    "* Stratified Split \n",
    "* Data Augmentations\n",
    "* Model Architecture Tweaking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c9ae1",
   "metadata": {
    "papermill": {
     "duration": 0.010884,
     "end_time": "2023-07-23T06:15:46.231225",
     "exception": false,
     "start_time": "2023-07-23T06:15:46.220341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model Performance Tracker**\n",
    "\n",
    "<style>\n",
    "table {\n",
    "    width: 100%;\n",
    "    border-collapse: collapse;\n",
    "}\n",
    "\n",
    "th, td {\n",
    "    padding: 8px;\n",
    "    text-align: left;\n",
    "}\n",
    "\n",
    "th {\n",
    "    background-color: #FF0000; /* Red color */\n",
    "    color: white;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><span style=\"color:red\">S.No.</span></th>\n",
    "        <th><span style=\"color:red\">Seed</span></th>\n",
    "        <th><span style=\"color:red\">Split</span></th>\n",
    "        <th><span style=\"color:red\">Model_name</span></th>\n",
    "        <th><span style=\"color:red\">DA</span></th>\n",
    "        <th><span style=\"color:red\">Others</span></th>\n",
    "        <th><span style=\"color:red\">CV</span></th>\n",
    "        <th><span style=\"color:red\">LB</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>42</td>\n",
    "        <td>Random</td>\n",
    "        <td>vanilla_bert_base_case</td>\n",
    "        <td>None</td>\n",
    "        <td>NA</td>\n",
    "        <td>0.4801</td>\n",
    "        <td>NA</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "        <td>NA</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b32218",
   "metadata": {
    "papermill": {
     "duration": 0.010794,
     "end_time": "2023-07-23T06:15:46.253342",
     "exception": false,
     "start_time": "2023-07-23T06:15:46.242548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.894314,
   "end_time": "2023-07-23T06:15:49.309284",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-23T06:15:06.414970",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
